{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c0dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ffbdc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen initialization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range= 0.2, \n",
    "    width_shift_range= 0.2,\n",
    "    height_shift_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip= True,\n",
    "    rescale= 1/255.0\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale= 1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d603725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#datagen usage\n",
    "train_images = train_datagen.flow_from_directory(\"Dataset\", target_size=(256,256), color_mode= 'rgb')\n",
    "test_images = test_datagen.flow_from_directory(\"validation_dataset\", target_size=(256,256), color_mode= 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7515ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building Deep model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db30c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN layers\n",
    "model.add(Conv2D(32, (3,3),activation = \"relu\", input_shape = (256,256,3)))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3),activation = \"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56378c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 239s 382ms/step - loss: 0.6629 - accuracy: 0.5985 - val_loss: 0.6188 - val_accuracy: 0.6610\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 252s 403ms/step - loss: 0.6337 - accuracy: 0.6414 - val_loss: 0.5888 - val_accuracy: 0.6956\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 241s 386ms/step - loss: 0.5998 - accuracy: 0.6765 - val_loss: 0.5571 - val_accuracy: 0.7200\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 240s 384ms/step - loss: 0.5804 - accuracy: 0.6923 - val_loss: 0.5270 - val_accuracy: 0.7434\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 240s 383ms/step - loss: 0.5527 - accuracy: 0.7155 - val_loss: 0.5050 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134d81f6688>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANN layers\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"sigmoid\"))\n",
    "model.compile(optimizer= \"adam\", loss= \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.fit(train_images, epochs= 5, validation_data= test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0455cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the model with a photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9a0f9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(\"test1\\\\7.jpg\", color_mode= \"rgb\", target_size= (256,256))\n",
    "img = img_to_array(img)/255.0\n",
    "img = img.reshape((1,)+img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7f70bea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d2fb6ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87527 , 0.126336]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img.shape\n",
    "predict = model.predict(img)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c3d4c220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f366c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
